{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic ReAct Agent using Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Block\n",
    "import openai\n",
    "import re\n",
    "import httpx\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "from openai import OpenAI \n",
    "# Initiate Open AI Client\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explanation of Agent Implementation\n",
    "- The `__init__` function is the constructor, which always has sytem prompt built in it. \n",
    "- It also saves messages in the `messages` variable. Start with the system message\n",
    "- The `__call__` function makes the Agent class callable, and executes the ai client call and appends results to messages\n",
    "- The following is the basic building block of agent call, no ReAct implementation yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Agent Class with constructor and make it callable\n",
    "class Agent:\n",
    "    def __init__(self, system=\"\"):\n",
    "        self.system = system\n",
    "        self.messages = []\n",
    "        if self.system:\n",
    "            self.messages.append({\"role\": \"system\", \"content\": system})\n",
    "\n",
    "    def __call__(self,message):\n",
    "        self.messages.append({\"role\": \"user\", \"content\": message})\n",
    "        result = self.execute()\n",
    "        self.messages.append({\"role\": \"assistant\", \"content\": result})\n",
    "        return result\n",
    "    \n",
    "    def execute(self):\n",
    "        chat_completion = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            temperature=0,\n",
    "            messages=self.messages,\n",
    "        )\n",
    "        return chat_completion.choices[0].message.content\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ReAct Agent Implementation\n",
    "- ReAct is a concent where the ai client is called in loops through the workflow : \n",
    "    1. Thought\n",
    "    2. Action\n",
    "    3. PAUSE\n",
    "    4. Observation\n",
    "- Continue the Loop as long as the ai client returns Observation as response\n",
    "- Stop the loop when ai client returns Answer instead of Observation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define System Prompt and Action mappings\n",
    "- System Prompt for ReAct agent is to elaborate on how we want the ai client to behave\n",
    "- Action mapping is a dictionary that let's ai client know about what actions/ api calls are available "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt= \"\"\" You run in a loop of Thought, Action, PAUSE, Observation.\n",
    "At the end of the loop you output an Answer\n",
    "Use Thought to describe your thoughts about the question you have been asked.\n",
    "Use Action to run one of the actions available to you - then return PAUSE.\n",
    "Observation will be the result of running those actions.\n",
    "\n",
    "Your available actions are:\n",
    "\n",
    "average_score:\n",
    "e.g. average score: 20 30 40 50\n",
    "Invokes the function average_score  by passing these numbers as input parameter as a list of float type numbers. And returns the output of the function. These list of numbers represent individual heat score of a game.\n",
    "\n",
    "heat_score:\n",
    "e.g. heat score: 2 6 6 7 8\n",
    "Invokes the function heat_score  by passing these numbers as input parameter as a list of float type numbers. And returns output of the function. These numbers represent various skill scores that an athelete receives by judges in an individual heat.\n",
    "\n",
    "Example session:\n",
    "\n",
    "Question: What is the average score of the athelete with the following heat scores: heat 1: 2 6 6 7 8 and heat 2 : 3 5 6 7 8\n",
    "Thought: I should look the average score using heat_score\n",
    "Action: heat_score: 2 6 6 7 8\n",
    "PAUSE\n",
    "\n",
    "You will be called again with this:\n",
    "\n",
    "Observation: The heat score is 29 and 29 \n",
    "\n",
    "You then output:\n",
    "\n",
    "Answer: The heat score is 29 and 29 \n",
    "\"\"\".strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the functions to go into known actions\n",
    "def average_score(scores):\n",
    "    return scores\n",
    "\n",
    "def heat_score(heat_scores):\n",
    "    # Add the elements of the input list\n",
    "    # total = 0\n",
    "    # for i in heat_scores:\n",
    "    #     total += float(i)\n",
    "    return heat_scores\n",
    "\n",
    "provisioned_actions = {\n",
    "    \"average_score\": average_score,\n",
    "    \"heat_score\": heat_score,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Invoke the Agent class, that has mechanism to call AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regular Expression to find Action \n",
    "action_reg_exp = re.compile(r'^Action: (\\w+): (.*)$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the query function to invoke ai agent and invoke action if needed\n",
    "def ai_query (question, max_turns=6):\n",
    "    i = 0\n",
    "    react_agent = Agent(system_prompt)\n",
    "    next_prompt = question\n",
    "    while i < max_turns:\n",
    "        i += 1\n",
    "        ai_response = react_agent(next_prompt)\n",
    "        print(f\"ai_response -> {ai_response}\")\n",
    "        # Find list of available actions\n",
    "        actions = [\n",
    "            action_reg_exp.match(a)\n",
    "            for a in ai_response.split(\"\\n\")\n",
    "            if action_reg_exp.match(a)\n",
    "        ]\n",
    "        print(f\"actions: {actions}\")\n",
    "\n",
    "        if actions: # ai response indicates that action is required\n",
    "            action, action_input = actions[0].groups()\n",
    "            print(f\"action: {action}\")\n",
    "            print(f\"action_input: {action_input}\")\n",
    "            if action not in provisioned_actions:\n",
    "                raise Exception(f\"Action {action} with Action Group {action_input} not found\")\n",
    "            print(f\"... Running {action} with {action_input}\")\n",
    "            observation = provisioned_actions[action](action_input)\n",
    "            print(f\"observation: {observation}\")\n",
    "            next_prompt = f\"Observation: {observation}\"\n",
    "        else:\n",
    "            return \n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Invoke the Agent with a user prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ai_response -> Thought: I should calculate the average score using the heat scores provided for heat One and heat Two.\n",
      "\n",
      "Action: heat_score: 2 6 6 7 8\n",
      "PAUSE\n",
      "actions: [<re.Match object; span=(0, 29), match='Action: heat_score: 2 6 6 7 8'>]\n",
      "action: heat_score\n",
      "action_input: 2 6 6 7 8\n",
      "... Running heat_score with 2 6 6 7 8\n",
      "observation: 2 6 6 7 8\n",
      "ai_response -> Thought: Now, I need to calculate the average score for heat One.\n",
      "\n",
      "Action: average_score: 2 6 6 7 8\n",
      "PAUSE\n",
      "actions: [<re.Match object; span=(0, 32), match='Action: average_score: 2 6 6 7 8'>]\n",
      "action: average_score\n",
      "action_input: 2 6 6 7 8\n",
      "... Running average_score with 2 6 6 7 8\n",
      "observation: 2 6 6 7 8\n",
      "ai_response -> Answer: The average score for heat One is 5.8.\n",
      "actions: []\n"
     ]
    }
   ],
   "source": [
    "user_prompt = \"\"\"I have the following heat scores: heat One score is 2,6,6,7,8 and heat Two scpre is 3,5,6,7,8. \n",
    "What is the average score of the athelete with these heat scores?\"\"\"\n",
    "ai_query(user_prompt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
