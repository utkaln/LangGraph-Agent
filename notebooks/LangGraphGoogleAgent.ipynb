{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "from langgraph.graph import StateGraph, END \n",
    "from typing import TypedDict, Annotated\n",
    "import operator\n",
    "from langchain_core.messages import  AnyMessage, SystemMessage, HumanMessage, ToolMessage\n",
    "from langgraph.checkpoint.memory import MemorySaver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Agent State so that the Graph can persist message value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = MemorySaver()\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], operator.add]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "google_search\n",
      "yahoo_finance_news\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.utilities import GoogleSearchAPIWrapper\n",
    "from langchain_core.tools import Tool\n",
    "from langchain_community.tools.yahoo_finance_news import YahooFinanceNewsTool\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "# Define tool that is available to langraph that an action edge can find\n",
    "tavily_tool = TavilySearchResults(max_results=3)\n",
    "\n",
    "google_search_wrapper = GoogleSearchAPIWrapper()\n",
    "\n",
    "search_tool = Tool(\n",
    "    name=\"google_search\",\n",
    "    description=\"Search Google for recent results.\",\n",
    "    func=google_search_wrapper.run,\n",
    ")\n",
    "\n",
    "yahoo_finance_tool = YahooFinanceNewsTool()\n",
    "print(search_tool.name)\n",
    "print(yahoo_finance_tool.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the Agent Class that performs:\n",
    "1. Call LLM in this example OpenAI\n",
    "2. Check if Action is present\n",
    "3. Take Action\n",
    "\n",
    "Steps in the code \n",
    "1. The constructor function takes model name, available tools choices and system prompt\n",
    "2. Start a LLM node\n",
    "3. Then add an action node\n",
    "4. Then define an action edge to link between LLM and action node. \n",
    "5. If no action decision made by LLM, then send to END node\n",
    "6. Create an edge to loop back to LLM node from Action Node\n",
    "7. Compile the graph and save it as class level attribute\n",
    "8. Create a dictionary of tools sent as parameters and save as class level attribute\n",
    "9. Save the tool name that sent as input as a class level attribute under the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self,model,tools,checkpointer, system=\"\"):\n",
    "        # Save the system message as a class level attribute\n",
    "        self.system = system\n",
    "\n",
    "        # Initialize the state graph that will have one LLM node, One Tool node and one Action Edge\n",
    "        graph = StateGraph(AgentState)\n",
    "        # Start Node\n",
    "        graph.add_node(\"llm\",self.call_llm)\n",
    "        \n",
    "        # Action Node that is available as tool\n",
    "        graph.add_node(\"action\",self.action_node)\n",
    "\n",
    "        # Decision Edge to decide to use action node\n",
    "        # First parameter is the node from which this edge is coming from \n",
    "        # Second parameter is the function that let's langraph explore tools\n",
    "        # Third parameter is available nodes after the decision either action node or END node\n",
    "        graph.add_conditional_edges(\"llm\",self.action_edge,{True: \"action\", False: END})\n",
    "\n",
    "        # Create Another edge to loop back to LLM node from action node\n",
    "        graph.add_edge(\"action\",\"llm\")\n",
    "\n",
    "        # Define what node the graph should start, in this case the llm\n",
    "        graph.set_entry_point(\"llm\")\n",
    "\n",
    "        # Once setup done compile the graph and Save the graph at the class level\n",
    "        self.graph = graph.compile(checkpointer=checkpointer)\n",
    "\n",
    "        # Create a dictionary of available tools sent to the constructor\n",
    "        self.tools = {tool.name: tool for tool in tools}\n",
    "\n",
    "        # Bind tools to model so that LLM can search for tools\n",
    "        self.model = model.bind_tools(tools)\n",
    "\n",
    "\n",
    "    # Define function for call llm node\n",
    "    def call_llm(self, state: AgentState):\n",
    "        # get the messages saved in the Agent state object\n",
    "        messages = state[\"messages\"]\n",
    "        # If system message is not blank, append that to the beginning of the messages\n",
    "        if self.system:\n",
    "            system_message= [SystemMessage(content=self.system)]\n",
    "            messages =  system_message + messages\n",
    "        # Call the model with the messages, it should return response as a single message\n",
    "        resp = self.model.invoke(messages)\n",
    "        print(f\"Response from LLM -> {resp}\")\n",
    "        # Return the response message as a list, that will be appended to the existing messages due to operator.add annotation at class level\n",
    "        return {\"messages\": [resp]}\n",
    "    \n",
    "    # Define function for call action node\n",
    "    def action_node(self, state: AgentState):\n",
    "        # get the last message from the Agent State, since the last message is the response from LLM that suggests to use the tool\n",
    "        # tool calls attribute is expected which has the name of the tool to be called\n",
    "        referred_tools_list = state[\"messages\"][-1].tool_calls\n",
    "        results = []\n",
    "\n",
    "        # Tool calls can be multiple tools, so iterate over them\n",
    "        for tool in referred_tools_list:\n",
    "            print(f\"Tool to be called -> {tool}\")\n",
    "            # invoke tool call by finding the name and the arguments as suggested by LLM\n",
    "            result = self.tools[tool[\"name\"]].invoke(tool[\"args\"])\n",
    "            # Append the result to the results list\n",
    "            results.append(ToolMessage(tool_call_id=tool[\"id\"], name=tool[\"name\"], content=str(result)))\n",
    "            \n",
    "        print(f\"Finished tool call ...\")\n",
    "        # returns results and add to the messages list at class level\n",
    "        return {\"messages\": results}\n",
    "    \n",
    "    # Define the actiton edge function that decides whether to look for tool or not\n",
    "    # If the last message in the message list has tool_calls attribute, then return True, else False\n",
    "    def action_edge(self, state: AgentState):\n",
    "        result = state[\"messages\"][-1]\n",
    "        return  len(result.tool_calls) > 0\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define LLM with Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"You are a smart research assistant. Use the search tool to look up information. \\\n",
    "Only look up information when you are sure of what you want. \\\n",
    "If you need to look up some information before asking a follow up question, you are allowed to do that!\n",
    "\"\"\"\n",
    "\n",
    "#from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "#llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\")\n",
    "llm = ChatOpenAI(model=os.getenv('OPENAI_LLM_GPT_4_O_mini'))\n",
    "ai_agent = Agent(llm,[search_tool],memory, system_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Invoke Agent Call with Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What is the latest news on the stock market?\n",
      "Response from LLM -> content='' additional_kwargs={'tool_calls': [{'id': 'call_uXZvvN4uaddjxg1aKF8cbKdg', 'function': {'arguments': '{\"query\":\"stock market\"}', 'name': 'yahoo_finance_news'}, 'type': 'function'}], 'refusal': None} response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 1070, 'total_tokens': 1088, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_44added55e', 'id': 'chatcmpl-BMSgk7XHbVl1mJp0UCfZ1qMaGiyq7', 'finish_reason': 'tool_calls', 'logprobs': None} id='run-d3203b9a-033f-4fbc-b704-53a46c27b7e5-0' tool_calls=[{'name': 'yahoo_finance_news', 'args': {'query': 'stock market'}, 'id': 'call_uXZvvN4uaddjxg1aKF8cbKdg', 'type': 'tool_call'}] usage_metadata={'input_tokens': 1070, 'output_tokens': 18, 'total_tokens': 1088, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  yahoo_finance_news (call_uXZvvN4uaddjxg1aKF8cbKdg)\n",
      " Call ID: call_uXZvvN4uaddjxg1aKF8cbKdg\n",
      "  Args:\n",
      "    query: stock market\n",
      "Tool to be called -> {'name': 'yahoo_finance_news', 'args': {'query': 'stock market'}, 'id': 'call_uXZvvN4uaddjxg1aKF8cbKdg', 'type': 'tool_call'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "404 Client Error: Not Found for url: https://query2.finance.yahoo.com/v10/finance/quoteSummary/STOCK%20MARKET?modules=financialData%2CquoteType%2CdefaultKeyStatistics%2CassetProfile%2CsummaryDetail&corsDomain=finance.yahoo.com&formatted=false&symbol=STOCK+MARKET&crumb=m%2FJgsO7SoVI\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'update'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[48]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Instead of invoke call stream\u001b[39;00m\n\u001b[32m      7\u001b[39m events = ai_agent.graph.stream(\n\u001b[32m      8\u001b[39m     {\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m: messages},\n\u001b[32m      9\u001b[39m     thread_id,\n\u001b[32m     10\u001b[39m     stream_mode=\u001b[33m\"\u001b[39m\u001b[33mvalues\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     11\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mevents\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpretty_print\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/code/LangGraph-Agent-OpenAI/venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py:2331\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[39m\n\u001b[32m   2325\u001b[39m     \u001b[38;5;66;03m# Similarly to Bulk Synchronous Parallel / Pregel model\u001b[39;00m\n\u001b[32m   2326\u001b[39m     \u001b[38;5;66;03m# computation proceeds in steps, while there are channel updates.\u001b[39;00m\n\u001b[32m   2327\u001b[39m     \u001b[38;5;66;03m# Channel updates from step N are only visible in step N+1\u001b[39;00m\n\u001b[32m   2328\u001b[39m     \u001b[38;5;66;03m# channels are guaranteed to be immutable for the duration of the step,\u001b[39;00m\n\u001b[32m   2329\u001b[39m     \u001b[38;5;66;03m# with channel updates applied only at the transition between steps.\u001b[39;00m\n\u001b[32m   2330\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m loop.tick(input_keys=\u001b[38;5;28mself\u001b[39m.input_channels):\n\u001b[32m-> \u001b[39m\u001b[32m2331\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2332\u001b[39m \u001b[43m            \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2333\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2334\u001b[39m \u001b[43m            \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2335\u001b[39m \u001b[43m            \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2336\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2337\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[32m   2338\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2339\u001b[39m \u001b[38;5;66;03m# emit output\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/code/LangGraph-Agent-OpenAI/venv/lib/python3.13/site-packages/langgraph/pregel/runner.py:146\u001b[39m, in \u001b[36mPregelRunner.tick\u001b[39m\u001b[34m(self, tasks, reraise, timeout, retry_policy, get_waiter)\u001b[39m\n\u001b[32m    144\u001b[39m t = tasks[\u001b[32m0\u001b[39m]\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m146\u001b[39m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    147\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    148\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    149\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    150\u001b[39m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[43m                \u001b[49m\u001b[43m_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    152\u001b[39m \u001b[43m                \u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    153\u001b[39m \u001b[43m                \u001b[49m\u001b[43mretry\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    154\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    155\u001b[39m \u001b[43m                \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    156\u001b[39m \u001b[43m                \u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    157\u001b[39m \u001b[43m                \u001b[49m\u001b[43mreraise\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreraise\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    158\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    159\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    160\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    161\u001b[39m     \u001b[38;5;28mself\u001b[39m.commit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    162\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/code/LangGraph-Agent-OpenAI/venv/lib/python3.13/site-packages/langgraph/pregel/retry.py:40\u001b[39m, in \u001b[36mrun_with_retry\u001b[39m\u001b[34m(task, retry_policy, configurable)\u001b[39m\n\u001b[32m     38\u001b[39m     task.writes.clear()\n\u001b[32m     39\u001b[39m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mproc\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     42\u001b[39m     ns: \u001b[38;5;28mstr\u001b[39m = config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/code/LangGraph-Agent-OpenAI/venv/lib/python3.13/site-packages/langgraph/utils/runnable.py:606\u001b[39m, in \u001b[36mRunnableSeq.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    602\u001b[39m config = patch_config(\n\u001b[32m    603\u001b[39m     config, callbacks=run_manager.get_child(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mseq:step:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;250m \u001b[39m+\u001b[38;5;250m \u001b[39m\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    604\u001b[39m )\n\u001b[32m    605\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m i == \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m606\u001b[39m     \u001b[38;5;28minput\u001b[39m = \u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    607\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    608\u001b[39m     \u001b[38;5;28minput\u001b[39m = step.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/code/LangGraph-Agent-OpenAI/venv/lib/python3.13/site-packages/langgraph/utils/runnable.py:371\u001b[39m, in \u001b[36mRunnableCallable.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    369\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    370\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m--> \u001b[39m\u001b[32m371\u001b[39m         ret = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    372\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.recurse:\n\u001b[32m    373\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ret.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[44]\u001b[39m\u001b[32m, line 61\u001b[39m, in \u001b[36mAgent.action_node\u001b[39m\u001b[34m(self, state)\u001b[39m\n\u001b[32m     59\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTool to be called -> \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtool\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     60\u001b[39m \u001b[38;5;66;03m# invoke tool call by finding the name and the arguments as suggested by LLM\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m61\u001b[39m result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtools\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtool\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mname\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtool\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43margs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     62\u001b[39m \u001b[38;5;66;03m# Append the result to the results list\u001b[39;00m\n\u001b[32m     63\u001b[39m results.append(ToolMessage(tool_call_id=tool[\u001b[33m\"\u001b[39m\u001b[33mid\u001b[39m\u001b[33m\"\u001b[39m], name=tool[\u001b[33m\"\u001b[39m\u001b[33mname\u001b[39m\u001b[33m\"\u001b[39m], content=\u001b[38;5;28mstr\u001b[39m(result)))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/code/LangGraph-Agent-OpenAI/venv/lib/python3.13/site-packages/langchain_core/tools/base.py:508\u001b[39m, in \u001b[36mBaseTool.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    501\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    502\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    503\u001b[39m     \u001b[38;5;28minput\u001b[39m: Union[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mdict\u001b[39m, ToolCall],\n\u001b[32m    504\u001b[39m     config: Optional[RunnableConfig] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    505\u001b[39m     **kwargs: Any,\n\u001b[32m    506\u001b[39m ) -> Any:\n\u001b[32m    507\u001b[39m     tool_input, kwargs = _prep_run_args(\u001b[38;5;28minput\u001b[39m, config, **kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m508\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtool_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/code/LangGraph-Agent-OpenAI/venv/lib/python3.13/site-packages/langchain_core/tools/base.py:763\u001b[39m, in \u001b[36mBaseTool.run\u001b[39m\u001b[34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, run_name, run_id, config, tool_call_id, **kwargs)\u001b[39m\n\u001b[32m    761\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m error_to_raise:\n\u001b[32m    762\u001b[39m     run_manager.on_tool_error(error_to_raise)\n\u001b[32m--> \u001b[39m\u001b[32m763\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m error_to_raise\n\u001b[32m    764\u001b[39m output = _format_output(content, artifact, tool_call_id, \u001b[38;5;28mself\u001b[39m.name, status)\n\u001b[32m    765\u001b[39m run_manager.on_tool_end(output, color=color, name=\u001b[38;5;28mself\u001b[39m.name, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/code/LangGraph-Agent-OpenAI/venv/lib/python3.13/site-packages/langchain_core/tools/base.py:732\u001b[39m, in \u001b[36mBaseTool.run\u001b[39m\u001b[34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, run_name, run_id, config, tool_call_id, **kwargs)\u001b[39m\n\u001b[32m    730\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m config_param := _get_runnable_config_param(\u001b[38;5;28mself\u001b[39m._run):\n\u001b[32m    731\u001b[39m         tool_kwargs = tool_kwargs | {config_param: config}\n\u001b[32m--> \u001b[39m\u001b[32m732\u001b[39m     response = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mtool_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mtool_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    733\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.response_format == \u001b[33m\"\u001b[39m\u001b[33mcontent_and_artifact\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    734\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(response) != \u001b[32m2\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/code/LangGraph-Agent-OpenAI/venv/lib/python3.13/site-packages/langchain_community/tools/yahoo_finance_news.py:58\u001b[39m, in \u001b[36mYahooFinanceNewsTool._run\u001b[39m\u001b[34m(self, query, run_manager)\u001b[39m\n\u001b[32m     56\u001b[39m company = yfinance.Ticker(query)\n\u001b[32m     57\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m58\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mcompany\u001b[49m\u001b[43m.\u001b[49m\u001b[43misin\u001b[49m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     59\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCompany ticker \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquery\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not found.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     60\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (HTTPError, ReadTimeout, \u001b[38;5;167;01mConnectionError\u001b[39;00m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/code/LangGraph-Agent-OpenAI/venv/lib/python3.13/site-packages/yfinance/ticker.py:111\u001b[39m, in \u001b[36mTicker.isin\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    109\u001b[39m \u001b[38;5;129m@property\u001b[39m\n\u001b[32m    110\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34misin\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m111\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_isin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/code/LangGraph-Agent-OpenAI/venv/lib/python3.13/site-packages/yfinance/base.py:529\u001b[39m, in \u001b[36mTickerBase.get_isin\u001b[39m\u001b[34m(self, proxy)\u001b[39m\n\u001b[32m    526\u001b[39m q = ticker\n\u001b[32m    528\u001b[39m \u001b[38;5;28mself\u001b[39m._quote.proxy = proxy \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.proxy\n\u001b[32m--> \u001b[39m\u001b[32m529\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_quote\u001b[49m\u001b[43m.\u001b[49m\u001b[43minfo\u001b[49m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    530\u001b[39m     \u001b[38;5;66;03m# Don't print error message cause self._quote.info will print one\u001b[39;00m\n\u001b[32m    531\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    532\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mshortName\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._quote.info:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/code/LangGraph-Agent-OpenAI/venv/lib/python3.13/site-packages/yfinance/scrapers/quote.py:508\u001b[39m, in \u001b[36mQuote.info\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    505\u001b[39m \u001b[38;5;129m@property\u001b[39m\n\u001b[32m    506\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minfo\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28mdict\u001b[39m:\n\u001b[32m    507\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._info \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m508\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fetch_info\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mproxy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    509\u001b[39m         \u001b[38;5;28mself\u001b[39m._fetch_complementary(\u001b[38;5;28mself\u001b[39m.proxy)\n\u001b[32m    511\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._info\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/code/LangGraph-Agent-OpenAI/venv/lib/python3.13/site-packages/yfinance/scrapers/quote.py:610\u001b[39m, in \u001b[36mQuote._fetch_info\u001b[39m\u001b[34m(self, proxy)\u001b[39m\n\u001b[32m    608\u001b[39m modules = [\u001b[33m'\u001b[39m\u001b[33mfinancialData\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mquoteType\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mdefaultKeyStatistics\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33massetProfile\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33msummaryDetail\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m    609\u001b[39m result = \u001b[38;5;28mself\u001b[39m._fetch(proxy, modules=modules)\n\u001b[32m--> \u001b[39m\u001b[32m610\u001b[39m \u001b[43mresult\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupdate\u001b[49m(\u001b[38;5;28mself\u001b[39m._fetch_additional_info(proxy))\n\u001b[32m    611\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    612\u001b[39m     \u001b[38;5;28mself\u001b[39m._info = {}\n",
      "\u001b[31mAttributeError\u001b[39m: 'NoneType' object has no attribute 'update'",
      "During task with name 'action' and id '5b2a9a1e-1f33-446c-cd6d-f9b9eb013c4e'"
     ]
    }
   ],
   "source": [
    "# Add a thread id to make the conversation persistent\n",
    "thread_id = {\"configurable\": {\"thread_id\":\"1\"}}\n",
    "user_prompt = \"What is the latest news on the stock market?\"\n",
    "messages = [HumanMessage(content=user_prompt)]\n",
    "\n",
    "# Instead of invoke call stream\n",
    "events = ai_agent.graph.stream(\n",
    "    {\"messages\": messages},\n",
    "    thread_id,\n",
    "    stream_mode=\"values\",\n",
    ")\n",
    "for event in events:\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
