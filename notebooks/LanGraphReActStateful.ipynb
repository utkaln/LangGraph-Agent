{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make Agentic Session Stateful for the user\n",
    "- To achive session statefulness a checkpointer is provided by Langraph\n",
    "- A database is used to keep track of checkpointer\n",
    "- For quick demo, a in memory database is used\n",
    "- Pass the checkpointer to graph.compile step\n",
    "- Add a thread number assigned to user session to keep track of the conversation\n",
    "- Modify the LangGraph to Stream by changing the `invoke` call to `stream` call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "memory = MemorySaver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tool name -> tavily_search_results_json\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "from langgraph.graph import StateGraph, END \n",
    "from typing import TypedDict, Annotated\n",
    "import operator\n",
    "from langchain_core.messages import  AnyMessage, SystemMessage, HumanMessage, ToolMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "# Define tool that is available to langraph that an action edge can find\n",
    "tool = TavilySearchResults(max_results=3)\n",
    "print(f\"tool name -> {tool.name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define A place holder for all the messages that is known as AgentState\n",
    "- This is a list of messages which keeps adding a new message everytime it is called"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], operator.add]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the Agent Class that performs:\n",
    "1. Call LLM in this example OpenAI\n",
    "2. Check if Action is present\n",
    "3. Take Action\n",
    "\n",
    "Steps in the code \n",
    "1. The constructor function takes model name, available tools choices and system prompt\n",
    "2. Start a LLM node\n",
    "3. Then add an action node\n",
    "4. Then define an action edge to link between LLM and action node. \n",
    "5. If no action decision made by LLM, then send to END node\n",
    "6. Create an edge to loop back to LLM node from Action Node\n",
    "7. Compile the graph and save it as class level attribute\n",
    "8. Create a dictionary of tools sent as parameters and save as class level attribute\n",
    "9. Save the tool name that sent as input as a class level attribute under the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self,model,tools,checkpointer, system=\"\"):\n",
    "        # Save the system message as a class level attribute\n",
    "        self.system = system\n",
    "\n",
    "        # Initialize the state graph that will have one LLM node, One Tool node and one Action Edge\n",
    "        graph = StateGraph(AgentState)\n",
    "        # Start Node\n",
    "        graph.add_node(\"llm\",self.call_openai)\n",
    "        \n",
    "        # Action Node that is available as tool\n",
    "        graph.add_node(\"action\",self.action_node)\n",
    "\n",
    "        # Decision Edge to decide to use action node\n",
    "        # First parameter is the node from which this edge is coming from \n",
    "        # Second parameter is the function that let's langraph explore tools\n",
    "        # Third parameter is available nodes after the decision either action node or END node\n",
    "        graph.add_conditional_edges(\"llm\",self.action_edge,{True: \"action\", False: END})\n",
    "\n",
    "        # Create Another edge to loop back to LLM node from action node\n",
    "        graph.add_edge(\"action\",\"llm\")\n",
    "\n",
    "        # Define what node the graph should start, in this case the llm\n",
    "        graph.set_entry_point(\"llm\")\n",
    "\n",
    "        # Once setup done compile the graph and Save the graph at the class level\n",
    "        self.graph = graph.compile(checkpointer=checkpointer)\n",
    "\n",
    "        # Create a dictionary of available tools sent to the constructor\n",
    "        self.tools = {tool.name: tool for tool in tools}\n",
    "\n",
    "        # Bind tools to model so that LLM can search for tools\n",
    "        self.model = model.bind_tools(tools)\n",
    "\n",
    "\n",
    "    # Define function for call llm node\n",
    "    def call_openai(self, state: AgentState):\n",
    "        # get the messages saved in the Agent state object\n",
    "        messages = state[\"messages\"]\n",
    "        # If system message is not blank, append that to the beginning of the messages\n",
    "        if self.system:\n",
    "            system_message= [SystemMessage(content=self.system)]\n",
    "            messages =  system_message + messages\n",
    "        # Call the model with the messages, it should return response as a single message\n",
    "        resp = self.model.invoke(messages)\n",
    "        print(f\"Response from LLM -> {resp}\")\n",
    "        # Return the response message as a list, that will be appended to the existing messages due to operator.add annotation at class level\n",
    "        return {\"messages\": [resp]}\n",
    "    \n",
    "    # Define function for call action node\n",
    "    def action_node(self, state: AgentState):\n",
    "        # get the last message from the Agent State, since the last message is the response from LLM that suggests to use the tool\n",
    "        # tool calls attribute is expected which has the name of the tool to be called\n",
    "        referred_tools_list = state[\"messages\"][-1].tool_calls\n",
    "        results = []\n",
    "\n",
    "        # Tool calls can be multiple tools, so iterate over them\n",
    "        for tool in referred_tools_list:\n",
    "            print(f\"Tool to be called -> {tool}\")\n",
    "            # invoke tool call by finding the name and the arguments as suggested by LLM\n",
    "            result = self.tools[tool[\"name\"]].invoke(tool[\"args\"])\n",
    "            # Append the result to the results list\n",
    "            results.append(ToolMessage(tool_call_id=tool[\"id\"], name=tool[\"name\"], content=str(result)))\n",
    "            \n",
    "        print(f\"Finished tool call ...\")\n",
    "        # returns results and add to the messages list at class level\n",
    "        return {\"messages\": results}\n",
    "    \n",
    "    # Define the actiton edge function that decides whether to look for tool or not\n",
    "    # If the last message in the message list has tool_calls attribute, then return True, else False\n",
    "    def action_edge(self, state: AgentState):\n",
    "        result = state[\"messages\"][-1]\n",
    "        return  len(result.tool_calls) > 0\n",
    "        \n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define a chat model with system prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = prompt = \"\"\"You are a smart research assistant. Use the search engine to look up information. \\\n",
    "You are allowed to make multiple calls (either together or in sequence). \\\n",
    "Only look up information when you are sure of what you want. \\\n",
    "If you need to look up some information before asking a follow up question, you are allowed to do that!\n",
    "\"\"\"\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "ai_agent = Agent(model,[tool],memory, system_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Invoke the langraph with user message as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Has Sunny Williams reach to earth from ISS from her last trip ? Has she given any statement after arrival ?\n",
      "Response from LLM -> content='' additional_kwargs={'tool_calls': [{'id': 'call_BZBEROdZrCLZ0ZXAEBBu7cu6', 'function': {'arguments': '{\"query\":\"Sunny Williams return to Earth from ISS statement\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}], 'refusal': None} response_metadata={'token_usage': {'completion_tokens': 27, 'prompt_tokens': 167, 'total_tokens': 194, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-BCbV003ZSdekqyEYU7XytYaHw5w4g', 'finish_reason': 'tool_calls', 'logprobs': None} id='run-d6d40170-2347-4538-abef-e6fb3a96c6d0-0' tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'Sunny Williams return to Earth from ISS statement'}, 'id': 'call_BZBEROdZrCLZ0ZXAEBBu7cu6', 'type': 'tool_call'}] usage_metadata={'input_tokens': 167, 'output_tokens': 27, 'total_tokens': 194, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  tavily_search_results_json (call_BZBEROdZrCLZ0ZXAEBBu7cu6)\n",
      " Call ID: call_BZBEROdZrCLZ0ZXAEBBu7cu6\n",
      "  Args:\n",
      "    query: Sunny Williams return to Earth from ISS statement\n",
      "Tool to be called -> {'name': 'tavily_search_results_json', 'args': {'query': 'Sunny Williams return to Earth from ISS statement'}, 'id': 'call_BZBEROdZrCLZ0ZXAEBBu7cu6', 'type': 'tool_call'}\n",
      "Finished tool call ...\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_search_results_json\n",
      "\n",
      "[{'title': \"NASA's Astronauts Finally Return To Earth I SpaceX Mission Live\", 'url': 'https://www.youtube.com/watch?v=XJf0_ndCaxs', 'content': ', according to a statement from NASA. Sunita Williams and Butch Wilmore, two NASA astronauts, are ultimately brought back to Earth from the', 'score': 0.78194773}, {'title': \"Sunita Williams Return LIVE Updates: NASA crew's unexpected 9 ...\", 'url': 'https://www.livemint.com/science/news/sunita-williams-return-live-updates-spacex-dragon-landing-nasa-astronaut-homecoming-butch-wilmore-crew-9-iss-18-march-11742276608885.html', 'content': 'NASA astronaut Sunita Williams is scheduled to return to Earth on March 19, 2025, after a nine-month mission aboard the International Space', 'score': 0.5709917777777777}, {'title': \"'Stranded' NASA astronauts carried away on stretchers after return ...\", 'url': 'https://www.livescience.com/space/space-exploration/stranded-nasa-astronauts-will-be-carried-away-on-stretchers-after-return-from-space-heres-why', 'content': \"Butch Wilmore and Suni Williams aboard the ISS in August 2024. When will the 'stranded' NASA astronauts return to Earth? The Crew-10 Dragon\", 'score': 0.4507377777777778}]\n",
      "Response from LLM -> content='Sunita Williams, along with Butch Wilmore, two NASA astronauts, has been brought back to Earth from the International Space Station (ISS) according to a statement from NASA. She returned to Earth after completing her mission. There is no specific statement mentioned in the search results about her comments after her arrival.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 65, 'prompt_tokens': 537, 'total_tokens': 602, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-BCbV2DSTE5MJWNUbqAU27nyd2cjo2', 'finish_reason': 'stop', 'logprobs': None} id='run-767ed535-21e8-414a-b9f5-d0c12c3554f6-0' usage_metadata={'input_tokens': 537, 'output_tokens': 65, 'total_tokens': 602, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Sunita Williams, along with Butch Wilmore, two NASA astronauts, has been brought back to Earth from the International Space Station (ISS) according to a statement from NASA. She returned to Earth after completing her mission. There is no specific statement mentioned in the search results about her comments after her arrival.\n"
     ]
    }
   ],
   "source": [
    "# Add a thread id to make the conversation persistent\n",
    "thread_id = {\"configurable\": {\"thread_id\":\"1\"}}\n",
    "user_prompt = \"Has Sunny Williams reach to earth from ISS from her last trip ? Has she given any statement after arrival ?\"\n",
    "messages = [HumanMessage(content=user_prompt)]\n",
    "\n",
    "# Instead of invoke call stream\n",
    "events = ai_agent.graph.stream(\n",
    "    {\"messages\": messages},\n",
    "    thread_id,\n",
    "    stream_mode=\"values\",\n",
    ")\n",
    "for event in events:\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continue the same conversation from above\n",
    "user_prompt = \"Where does her family leave? What is her work place in USA?\"\n",
    "messages = [HumanMessage(content=user_prompt)]\n",
    "\n",
    "# Instead of invoke call stream\n",
    "events = ai_agent.graph.stream(\n",
    "    {\"messages\": messages},\n",
    "    thread_id,\n",
    "    stream_mode=\"values\",\n",
    ")\n",
    "for event in events:\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
