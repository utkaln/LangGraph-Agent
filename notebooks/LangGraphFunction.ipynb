{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "import operator\n",
    "from langchain_core.messages import  AnyMessage, SystemMessage, HumanMessage, ToolMessage\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define System Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\" You are an event manager planning a seminar about various software engineering topics happening at Hunt Valley, Maryland. \n",
    "The user will ask you to inquire about topics of the seminar.\n",
    "\n",
    "To provide information about the seminar and users wanting to register for the seminar, you need to use the tools provided. \n",
    "Your job to interact with a SQL database.\n",
    "Given an input question, create a syntactically correct SQLite query to run, then look at the results of the query and return the answer.\n",
    "Unless the user specifies a specific number of examples they wish to obtain, always limit your query to at most 10 results.\n",
    "You can order the results by a relevant column to return the most interesting examples in the database.\n",
    "Never query for all the columns from a specific table, only ask for the relevant columns given the question.\n",
    "You have access to tools for interacting with the database.\n",
    "Only use the below tools. Only use the information returned by the below tools to construct your final answer.\n",
    "You MUST double check your query before executing it. If you get an error while executing a query, rewrite the query and try again.\n",
    "\n",
    "DO NOT make any DML statements (INSERT, UPDATE, DELETE, DROP etc.) to the database.\n",
    "\n",
    "To start you should ALWAYS look at the tables in the database to see what you can query.\n",
    "Do NOT skip this step.\n",
    "Then you should query the schema of the most relevant tables. Only use the following tables : \n",
    "    - seminars\n",
    "    - users\n",
    "\n",
    "\n",
    "The user will ask you to register for certain sessions, you need to ask them the required information and register for the topics.\n",
    "\n",
    "Always confirm with user before registering them for any topic.\n",
    "\n",
    "Allow the user to modify or cancel their registration.\n",
    "\n",
    "The user may inquire about their existing registrations, you need to provide them with the list of topics they are registered for.\n",
    "\n",
    "If certain topic that is not available as session, then note down the feedback from the user and thank them. But do not register for any topic that you are not provided with.\n",
    "\n",
    "Keep the chat limited to only the seminar topics and registration.\n",
    "\n",
    "If any of the tools are not available, then you need to inform the user about it and tell that this will be added in the next version.\n",
    "\n",
    "Do not engage into any emotional or intimate conversations with the user, politely decline if the user starts such a topic.\n",
    "\n",
    "At the end of a successful registration offer the user to book nearby hotels and suggest food options. For this you can use the TavilySearchResults tool.\n",
    "\n",
    "You can also provide information about tourist places and current weather using TavilySearchResults tool.\n",
    "\"\"\"\n",
    "\n",
    "welcome_prompt = \"\"\"Welcome to the Technology seminar of North Maryland Area. How can I assist you today? When you are done chatting, please write bye to end\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define state to add every message added to the context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegistrationState(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    messages: Annotated[list[AnyMessage], operator.add]\n",
    "\n",
    "memory = MemorySaver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Database (Local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "# Connect to the database (or create if it doesn't exist)\n",
    "conn = sqlite3.connect('event_data.db')\n",
    "\n",
    "# Create a cursor object\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Create Event table\n",
    "cursor.execute('''\n",
    "    CREATE TABLE IF NOT EXISTS seminars (\n",
    "        event_id INTEGER PRIMARY KEY,\n",
    "        event_name TEXT,\n",
    "        host_name TEXT,\n",
    "        event_date TEXT,\n",
    "        event_time TEXT,\n",
    "        event_location TEXT,\n",
    "        event_desc TEXT,\n",
    "        event_type TEXT,\n",
    "        event_duration TEXT,\n",
    "        event_capacity INTEGER\n",
    "    )\n",
    "''')\n",
    "\n",
    "# Create Registrant table\n",
    "cursor.execute('''\n",
    "    CREATE TABLE IF NOT EXISTS users (\n",
    "        user_id INTEGER PRIMARY KEY,\n",
    "        user_email TEXT,\n",
    "        user_name TEXT,\n",
    "        user_reg_events TEXT,\n",
    "        user_wait_events TEXT\n",
    "    )\n",
    "''')\n",
    "\n",
    "# Insert data\n",
    "cursor.execute(\"INSERT INTO seminars (event_id, event_name, host_name, event_date, event_time, event_location, event_desc, event_type, event_duration, event_capacity ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\", (1,'Agent AI for HealthCare', 'Utkal Nayak', '2025-04-15', '17:00', 'Hunt Valley, MD', 'Agent AI for HealthCare - Onboarding','LAB','120',20))\n",
    "cursor.execute(\"INSERT INTO users (user_id, user_email, user_name, user_reg_events, user_wait_events) VALUES (?, ?, ?, ?, ?)\", (1,'utkalnayak@yahoo.com', 'Utkal Nayak', '1', ''))\n",
    "\n",
    "\n",
    "# Commit the changes\n",
    "conn.commit()\n",
    "\n",
    "# Retrieve data\n",
    "# cursor.execute(\"SELECT * FROM seminars\")\n",
    "\n",
    "# rows = cursor.fetchall()\n",
    "# for row in rows:\n",
    "#     print(row)\n",
    "\n",
    "# cursor.execute(\"SELECT * FROM users\")\n",
    "# rows = cursor.fetchall()\n",
    "# for row in rows:\n",
    "#     print(row)\n",
    "# Close the connection\n",
    "# conn.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define LLM and SQL Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seminars, users\n",
      "\n",
      "CREATE TABLE seminars (\n",
      "\tevent_id INTEGER, \n",
      "\tevent_name TEXT, \n",
      "\thost_name TEXT, \n",
      "\tevent_date TEXT, \n",
      "\tevent_time TEXT, \n",
      "\tevent_location TEXT, \n",
      "\tevent_desc TEXT, \n",
      "\tevent_type TEXT, \n",
      "\tevent_duration TEXT, \n",
      "\tevent_capacity INTEGER, \n",
      "\tPRIMARY KEY (event_id)\n",
      ")\n",
      "\n",
      "/*\n",
      "3 rows from seminars table:\n",
      "event_id\tevent_name\thost_name\tevent_date\tevent_time\tevent_location\tevent_desc\tevent_type\tevent_duration\tevent_capacity\n",
      "1\tAgent AI for HealthCare\tUtkal Nayak\t2025-04-15\t17:00\tHunt Valley, MD\tAgent AI for HealthCare - Onboarding\tLAB\t120\t20\n",
      "*/\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.agent_toolkits import SQLDatabaseToolkit\n",
    "from langchain import hub\n",
    "from typing_extensions import Annotated\n",
    "query_prompt_template = hub.pull(\"langchain-ai/sql-query-system-prompt\")\n",
    "\n",
    "from langchain_community.utilities import SQLDatabase\n",
    "db = SQLDatabase.from_uri(\"sqlite:///event_data.db\")\n",
    "db.run(\"SELECT * FROM seminars\")\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\")\n",
    "\n",
    "tool_kit = SQLDatabaseToolkit(db=db, llm=llm)\n",
    "tools = tool_kit.get_tools()\n",
    "list_tables_tool = next(tool for tool in tools if tool.name == \"sql_db_list_tables\")\n",
    "get_schema_tool = next(tool for tool in tools if tool.name == \"sql_db_schema\")\n",
    "print(list_tables_tool.invoke(\"\"))\n",
    "print(get_schema_tool.invoke(\"seminars\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert User Question to SQL Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/utkalnayak/Documents/code/LangGraph-Agent-OpenAI/venv/lib/python3.13/site-packages/langchain_google_genai/chat_models.py:1410: UserWarning: ChatGoogleGenerativeAI.with_structured_output with dict schema has changed recently to align with behavior of other LangChain chat models. More context: https://github.com/langchain-ai/langchain-google/pull/772\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'query': 'SELECT count(*) FROM seminars'}"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "class QueryOutput(TypedDict):\n",
    "    \"\"\"Generated SQL query.\"\"\"\n",
    "\n",
    "    query: Annotated[str, ..., \"Syntactically valid SQL query.\"]\n",
    "\n",
    "def write_query(state: RegistrationState):\n",
    "    \"\"\"Generate SQL query to fetch information.\"\"\"\n",
    "    prompt = query_prompt_template.invoke(\n",
    "        {\n",
    "            \"dialect\": db.dialect,\n",
    "            \"top_k\": 10,\n",
    "            \"table_info\": db.get_table_info(),\n",
    "            \"input\": state[\"question\"],\n",
    "        }\n",
    "    )\n",
    "    structured_llm = llm.with_structured_output(QueryOutput)\n",
    "    result = structured_llm.invoke(prompt)\n",
    "    return {\"query\": result[\"query\"]}\n",
    "\n",
    "write_query({\"question\": \"How many Events are there?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'result': '[(1,)]'}"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.tools.sql_database.tool import QuerySQLDatabaseTool\n",
    "\n",
    "\n",
    "def execute_query(state: RegistrationState):\n",
    "    \"\"\"Execute SQL query.\"\"\"\n",
    "    execute_query_tool = QuerySQLDatabaseTool(db=db)\n",
    "    return {\"result\": execute_query_tool.invoke(state[\"query\"])}\n",
    "\n",
    "execute_query({\"query\": \"SELECT COUNT(*) AS EventCount FROM seminars;\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answer(state: RegistrationState):\n",
    "    \"\"\"Answer question using retrieved information as context.\"\"\"\n",
    "    prompt = (\n",
    "        \"Given the following user question, corresponding SQL query, \"\n",
    "        \"and SQL result, answer the user question.\\n\\n\"\n",
    "        f'Question: {state[\"question\"]}\\n'\n",
    "        f'SQL Query: {state[\"query\"]}\\n'\n",
    "        f'SQL Result: {state[\"result\"]}'\n",
    "    )\n",
    "    response = llm.invoke(prompt)\n",
    "    return {\"answer\": response.content}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Simple Graph to Run SQL Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langgraph.graph import START, StateGraph\n",
    "\n",
    "graph_builder = StateGraph(RegistrationState).add_sequence(\n",
    "    [write_query, execute_query, generate_answer]\n",
    ")\n",
    "graph_builder.add_edge(START, \"write_query\")\n",
    "graph = graph_builder.compile()\n",
    "\n",
    "# Optional\n",
    "from IPython.display import Image, display\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Invoke LLM to execute queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'question'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[123]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mquestion\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mWhat can you do for me?\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mupdates\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m      3\u001b[39m \u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/code/LangGraph-Agent-OpenAI/venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py:2331\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[39m\n\u001b[32m   2325\u001b[39m     \u001b[38;5;66;03m# Similarly to Bulk Synchronous Parallel / Pregel model\u001b[39;00m\n\u001b[32m   2326\u001b[39m     \u001b[38;5;66;03m# computation proceeds in steps, while there are channel updates.\u001b[39;00m\n\u001b[32m   2327\u001b[39m     \u001b[38;5;66;03m# Channel updates from step N are only visible in step N+1\u001b[39;00m\n\u001b[32m   2328\u001b[39m     \u001b[38;5;66;03m# channels are guaranteed to be immutable for the duration of the step,\u001b[39;00m\n\u001b[32m   2329\u001b[39m     \u001b[38;5;66;03m# with channel updates applied only at the transition between steps.\u001b[39;00m\n\u001b[32m   2330\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m loop.tick(input_keys=\u001b[38;5;28mself\u001b[39m.input_channels):\n\u001b[32m-> \u001b[39m\u001b[32m2331\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2332\u001b[39m \u001b[43m            \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2333\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2334\u001b[39m \u001b[43m            \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2335\u001b[39m \u001b[43m            \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2336\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2337\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[32m   2338\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2339\u001b[39m \u001b[38;5;66;03m# emit output\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/code/LangGraph-Agent-OpenAI/venv/lib/python3.13/site-packages/langgraph/pregel/runner.py:146\u001b[39m, in \u001b[36mPregelRunner.tick\u001b[39m\u001b[34m(self, tasks, reraise, timeout, retry_policy, get_waiter)\u001b[39m\n\u001b[32m    144\u001b[39m t = tasks[\u001b[32m0\u001b[39m]\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m146\u001b[39m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    147\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    148\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    149\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    150\u001b[39m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[43m                \u001b[49m\u001b[43m_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    152\u001b[39m \u001b[43m                \u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    153\u001b[39m \u001b[43m                \u001b[49m\u001b[43mretry\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    154\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    155\u001b[39m \u001b[43m                \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    156\u001b[39m \u001b[43m                \u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    157\u001b[39m \u001b[43m                \u001b[49m\u001b[43mreraise\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreraise\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    158\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    159\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    160\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    161\u001b[39m     \u001b[38;5;28mself\u001b[39m.commit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    162\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/code/LangGraph-Agent-OpenAI/venv/lib/python3.13/site-packages/langgraph/pregel/retry.py:40\u001b[39m, in \u001b[36mrun_with_retry\u001b[39m\u001b[34m(task, retry_policy, configurable)\u001b[39m\n\u001b[32m     38\u001b[39m     task.writes.clear()\n\u001b[32m     39\u001b[39m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mproc\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     42\u001b[39m     ns: \u001b[38;5;28mstr\u001b[39m = config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/code/LangGraph-Agent-OpenAI/venv/lib/python3.13/site-packages/langgraph/utils/runnable.py:606\u001b[39m, in \u001b[36mRunnableSeq.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    602\u001b[39m config = patch_config(\n\u001b[32m    603\u001b[39m     config, callbacks=run_manager.get_child(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mseq:step:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;250m \u001b[39m+\u001b[38;5;250m \u001b[39m\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    604\u001b[39m )\n\u001b[32m    605\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m i == \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m606\u001b[39m     \u001b[38;5;28minput\u001b[39m = \u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    607\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    608\u001b[39m     \u001b[38;5;28minput\u001b[39m = step.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/code/LangGraph-Agent-OpenAI/venv/lib/python3.13/site-packages/langgraph/utils/runnable.py:371\u001b[39m, in \u001b[36mRunnableCallable.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    369\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    370\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m--> \u001b[39m\u001b[32m371\u001b[39m         ret = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    372\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.recurse:\n\u001b[32m    373\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ret.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[118]\u001b[39m\u001b[32m, line 13\u001b[39m, in \u001b[36mwrite_query\u001b[39m\u001b[34m(state)\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrite_query\u001b[39m(state: RegistrationState):\n\u001b[32m      7\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Generate SQL query to fetch information.\"\"\"\u001b[39;00m\n\u001b[32m      8\u001b[39m     prompt = query_prompt_template.invoke(\n\u001b[32m      9\u001b[39m         {\n\u001b[32m     10\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mdialect\u001b[39m\u001b[33m\"\u001b[39m: db.dialect,\n\u001b[32m     11\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mtop_k\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m10\u001b[39m,\n\u001b[32m     12\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mtable_info\u001b[39m\u001b[33m\"\u001b[39m: db.get_table_info(),\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33minput\u001b[39m\u001b[33m\"\u001b[39m: \u001b[43mstate\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mquestion\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m,\n\u001b[32m     14\u001b[39m         }\n\u001b[32m     15\u001b[39m     )\n\u001b[32m     16\u001b[39m     structured_llm = llm.with_structured_output(QueryOutput)\n\u001b[32m     17\u001b[39m     result = structured_llm.invoke(prompt)\n",
      "\u001b[31mKeyError\u001b[39m: 'question'",
      "During task with name 'write_query' and id '8afefac8-3986-7e89-d354-905f961c192c'"
     ]
    }
   ],
   "source": [
    "for step in graph.stream(\n",
    "    {\"question\": \"What can you do for me?\"}, stream_mode=\"updates\"\n",
    "):\n",
    "    print(step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define functions to interact with DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_tables():\n",
    "    # Create a cursor object\n",
    "    cursor = conn.cursor()\n",
    "    # Fetch the table names.\n",
    "    cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "    tables = cursor.fetchall()\n",
    "    return [t[0] for t in tables]\n",
    "\n",
    "list_tables()\n",
    "\n",
    "def describe_table(table_name: str) -> list[tuple[str, str]]:\n",
    "     # Create a cursor object\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(f\"PRAGMA table_info({table_name});\")\n",
    "    schema = cursor.fetchall()\n",
    "    return [(col[1], col[2]) for col in schema]\n",
    "\n",
    "describe_table('seminars')\n",
    "\n",
    "\n",
    "def execute_query(sql: str) -> list[list[str]]:\n",
    "    print(f\"Executing SQL: {sql}\")\n",
    "     # Create a cursor object\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(sql)\n",
    "    return cursor.fetchall()\n",
    "\n",
    "execute_query(\"SELECT * FROM seminars\")\n",
    "\n",
    "\n",
    "def db_tools_list():\n",
    "    return [list_tables, describe_table, execute_query]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Functions for Table Data Interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/utkalnayak/Documents/code/LangGraph-Agent-OpenAI/venv/lib/python3.13/site-packages/langchain_google_genai/chat_models.py:1410: UserWarning: ChatGoogleGenerativeAI.with_structured_output with dict schema has changed recently to align with behavior of other LangChain chat models. More context: https://github.com/langchain-ai/langchain-google/pull/772\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "class QueryOutput(TypedDict):\n",
    "    \"\"\"Generated SQL query.\"\"\"\n",
    "\n",
    "    query: Annotated[str, ..., \"Syntactically valid SQL query.\"]\n",
    "\n",
    "def write_query(prompt: str):\n",
    "    \"\"\"Generate SQL query to fetch information.\"\"\"\n",
    "    structured_llm = llm.with_structured_output(QueryOutput)\n",
    "    result = structured_llm.invoke(system_prompt)\n",
    "    return {\"query\": result[\"query\"]}\n",
    "\n",
    "write_query({\"question\": \"How many Events are there?\"})\n",
    "\n",
    "@tool\n",
    "def db_query_tool(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Execute a SQL query against the database and get back the result.\n",
    "    If the query is not correct, an error message will be returned.\n",
    "    If an error is returned, rewrite the query, check the query, and try again.\n",
    "    \"\"\"\n",
    "    result = db.run_no_throw(query)\n",
    "    if not result:\n",
    "        return \"Error: Query failed. Please rewrite your query and try again.\"\n",
    "    return result\n",
    "\n",
    "#print(db_query_tool.invoke(\"SELECT * FROM seminars\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define LLM node and other nodes for the State Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegistrationAgent:\n",
    "    def __init__(self,model,tools,checkpointer, system=\"\"):\n",
    "        # Save the system message as a class level attribute\n",
    "        self.system = system\n",
    "\n",
    "        # Initialize the state graph that will have one LLM node, One Tool node and one Action Edge\n",
    "        graph = StateGraph(RegistrationState)\n",
    "        # Start Node\n",
    "        graph.add_node(\"llm\",self.call_llm)\n",
    "        \n",
    "        # Action Node that is available as tool\n",
    "        graph.add_node(\"action\",self.action_node)\n",
    "\n",
    "        # Decision Edge to decide to use action node\n",
    "        # First parameter is the node from which this edge is coming from \n",
    "        # Second parameter is the function that let's langraph explore tools\n",
    "        # Third parameter is available nodes after the decision either action node or END node\n",
    "        graph.add_conditional_edges(\"llm\",self.action_edge_decision,{True: \"action\", False: END})\n",
    "\n",
    "        # Create Another edge to loop back to LLM node from action node\n",
    "        graph.add_edge(\"action\",\"llm\")\n",
    "\n",
    "        # Define what node the graph should start, in this case the llm\n",
    "        graph.set_entry_point(\"llm\")\n",
    "\n",
    "        # Once setup done compile the graph and Save the graph at the class level\n",
    "        self.graph = graph.compile(checkpointer=checkpointer)\n",
    "\n",
    "        # Create a dictionary of available tools sent to the constructor\n",
    "        self.tools = {tool.name: tool for tool in tools}\n",
    "\n",
    "        # Bind tools to model so that LLM can search for tools\n",
    "        self.model = model.bind_tools(tools)\n",
    "\n",
    "\n",
    "    # Define function for call llm node\n",
    "    def call_llm(self, state: RegistrationState):\n",
    "        # get the messages saved in the Agent state object\n",
    "        messages = state[\"messages\"]\n",
    "        # If system message is not blank, append that to the beginning of the messages\n",
    "        if self.system:\n",
    "            system_message= [SystemMessage(content=self.system)]\n",
    "            messages =  system_message + messages\n",
    "        # Call the model with the messages, it should return response as a single message\n",
    "        resp = self.model.invoke(messages)\n",
    "        print(f\"Response from LLM -> {resp}\")\n",
    "        # Return the response message as a list, that will be appended to the existing messages due to operator.add annotation at class level\n",
    "        return {\"messages\": [resp]}\n",
    "    \n",
    "    # Define function for call action node\n",
    "    def action_node(self, state: RegistrationState):\n",
    "        # get the last message from the Agent State, since the last message is the response from LLM that suggests to use the tool\n",
    "        # tool calls attribute is expected which has the name of the tool to be called\n",
    "        referred_tools_list = state[\"messages\"][-1].tool_calls\n",
    "        results = []\n",
    "\n",
    "        # Tool calls can be multiple tools, so iterate over them\n",
    "        for tool in referred_tools_list:\n",
    "            print(f\"Tool to be called -> {tool}\")\n",
    "            # invoke tool call by finding the name and the arguments as suggested by LLM\n",
    "            result = self.tools[tool[\"name\"]].invoke(tool[\"args\"])\n",
    "            # Append the result to the results list\n",
    "            results.append(ToolMessage(tool_call_id=tool[\"id\"], name=tool[\"name\"], content=str(result)))\n",
    "            \n",
    "        print(f\"Finished tool call ...\")\n",
    "        # returns results and add to the messages list at class level\n",
    "        return {\"messages\": results}\n",
    "    \n",
    "    # Define the actiton edge function that decides whether to look for tool or not\n",
    "    # If the last message in the message list has tool_calls attribute, then return True, else False\n",
    "    def action_edge_decision(self, state: RegistrationState):\n",
    "        result = state[\"messages\"][-1]\n",
    "        return  len(result.tool_calls) > 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare LLM with Agent Graph and Memory configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_tool = TavilySearchResults(max_results=3)\n",
    "reg_agent = RegistrationAgent(llm,[search_tool, db_tools],memory, system_prompt)\n",
    "# Add a thread id to make the conversation persistent\n",
    "thread_id = {\"configurable\": {\"thread_id\":\"1\"}}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Invoke Model\n",
    "- Apply recursive limit so that the chat will end after these many calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = [HumanMessage(content=input(\"User : \"))]\n",
    "events = reg_agent.graph.stream(\n",
    "    {\"messages\": user_input},\n",
    "    thread_id,\n",
    "    stream_mode=\"values\",\n",
    ")\n",
    "for event in events:\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
